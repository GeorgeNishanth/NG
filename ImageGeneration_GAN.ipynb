{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeNishanth/NG/blob/main/ImageGeneration_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "Sziiq0XVbyzA",
        "outputId": "11fb45fa-59b3-4fa2-af1a-31beb8de3835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Set TensorFlow logging level\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# Reset the default graph (for TensorFlow 2.x)\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "# Load the MNIST dataset using Keras\n",
        "(x_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "# Normalize the data to [0, 1]\n",
        "x_train = x_train / 255.0\n",
        "\n",
        "# Display the 14th image (index 13)\n",
        "plt.imshow(x_train[13], cmap=\"gray\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUBEuxWieKYE"
      },
      "outputs": [],
      "source": [
        "def generator(z,reuse=None):\n",
        "\n",
        "    with tf.variable_scope('generator',reuse=reuse):\n",
        "\n",
        "        hidden1 = tf.layers.dense(inputs=z,units=128,activation=tf.nn.leaky_relu)\n",
        "        hidden2 = tf.layers.dense(inputs=hidden1,units=128,activation=tf.nn.leaky_relu)\n",
        "        output = tf.layers.dense(inputs=hidden2,units=784,activation=tf.nn.tanh)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U7GS3Emei86"
      },
      "outputs": [],
      "source": [
        "def discriminator(X,reuse=None):\n",
        "\n",
        "    with tf.variable_scope('discriminator',reuse=reuse):\n",
        "\n",
        "        hidden1 = tf.layers.dense(inputs=X,units=128,activation=tf.nn.leaky_relu)\n",
        "        hidden2 = tf.layers.dense(inputs=hidden1,units=128,activation=tf.nn.leaky_relu)\n",
        "        logits = tf.layers.dense(inputs=hidden2,units=1)\n",
        "        output = tf.sigmoid(logits)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3_htt65escO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define input shapes using Keras layers (instead of placeholders)\n",
        "x = tf.keras.Input(shape=(784,))  # Input for images (28x28 flattened)\n",
        "z = tf.keras.Input(shape=(100,))  # Input for random noise\n",
        "\n",
        "# Continue defining your model here...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-35k6GmevO5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the generator model using Keras\n",
        "class Generator(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(784, activation='sigmoid')  # Output layer (flattened 28x28)\n",
        "\n",
        "    def call(self, z):\n",
        "        x = self.dense1(z)\n",
        "        fake_x = self.dense2(x)\n",
        "        return fake_x\n",
        "\n",
        "# Instantiate the generator model\n",
        "generator = Generator()\n",
        "\n",
        "# Pass noise vector 'z' through the generator\n",
        "fake_x = generator(z)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fznjW_-HfHju"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the discriminator model using Keras\n",
        "class Discriminator(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(128, activation=tf.nn.leaky_relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer (real or fake)\n",
        "\n",
        "    def call(self, X):\n",
        "        x = self.dense1(X)\n",
        "        D_logits_real = self.dense2(x)\n",
        "        return D_logits_real\n",
        "\n",
        "# Instantiate the discriminator model\n",
        "discriminator = Discriminator()\n",
        "\n",
        "# Pass real image 'x' through the discriminator\n",
        "D_logits_real = discriminator(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5dqo-ArJuWD"
      },
      "outputs": [],
      "source": [
        "# Pass fake image 'fake_x' through the discriminator (no need for 'reuse')\n",
        "D_logits_fake = discriminator(fake_x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oITIJQgwKBmp",
        "outputId": "b4d1d537-b539-41ed-c998-4a9c650e8b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.99562377, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Assuming the discriminator is defined using tf.keras.Model\n",
        "class Discriminator(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(128, activation=tf.nn.leaky_relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(1, activation=None)  # Logits (no activation on output)\n",
        "\n",
        "    def call(self, X):\n",
        "        x = self.dense1(X)\n",
        "        D_logits_real = self.dense2(x)\n",
        "        return D_logits_real\n",
        "\n",
        "# Instantiate the discriminator model\n",
        "discriminator = Discriminator()\n",
        "\n",
        "# Ensure x is a tf.Tensor (real images)\n",
        "# Example: Assuming x is your input image tensor\n",
        "x = tf.random.normal([32, 784])  # Example real images batch (32 examples, 784 features)\n",
        "\n",
        "# Ensure D_logits_real is a TensorFlow tensor\n",
        "D_logits_real = discriminator(x)  # Pass the input x (real images)\n",
        "\n",
        "# Compute the discriminator loss for real images\n",
        "@tf.function\n",
        "def compute_D_loss_real(D_logits_real):\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "        logits=D_logits_real,\n",
        "        labels=tf.ones_like(D_logits_real)  # Labels are 1 for real images\n",
        "    ))\n",
        "\n",
        "# Call the loss function\n",
        "D_loss_real = compute_D_loss_real(D_logits_real)\n",
        "\n",
        "print(D_loss_real)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcEmOjpvLT1i",
        "outputId": "3f092328-6190-4df4-a373-9e55ef60d26d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(1.0662465, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define your Discriminator model\n",
        "class Discriminator(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(128, activation=tf.nn.leaky_relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(1, activation=None)  # Logits (no activation on output)\n",
        "\n",
        "    def call(self, X):\n",
        "        x = self.dense1(X)\n",
        "        D_logits_fake = self.dense2(x)\n",
        "        return D_logits_fake\n",
        "\n",
        "# Instantiate the discriminator model\n",
        "discriminator = Discriminator()\n",
        "\n",
        "# Create input tensor for fake images\n",
        "# Example: Assuming z is the input noise tensor\n",
        "z = tf.random.normal([32, 100])  # Example batch size of 32, noise vector of size 100\n",
        "\n",
        "# Generate fake images using the generator (example fake_x)\n",
        "fake_x = generator(z)  # Assuming you have a generator model\n",
        "\n",
        "# Pass the fake images through the discriminator\n",
        "D_logits_fake = discriminator(fake_x)  # This will give the logits for fake images\n",
        "\n",
        "# Compute the discriminator loss for fake images\n",
        "@tf.function\n",
        "def compute_D_loss_fake(D_logits_fake):\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "        logits=D_logits_fake,\n",
        "        labels=tf.zeros_like(D_logits_fake)  # Labels are 0 for fake images\n",
        "    ))\n",
        "\n",
        "# Call the loss function\n",
        "D_loss_fake = compute_D_loss_fake(D_logits_fake)\n",
        "\n",
        "print(D_loss_fake)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s54NiUgnLsml",
        "outputId": "2d26a6be-3551-4cfa-9667-9449fc6295b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=2.0618703>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " D_loss_real + D_loss_fake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoqarP7gMCzZ"
      },
      "outputs": [],
      "source": [
        "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "    logits=D_logits_fake,\n",
        "    labels=tf.ones_like(D_logits_fake)  # Generator wants the fake images to be classified as real\n",
        "))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRkD4nanMDWU"
      },
      "outputs": [],
      "source": [
        "# Get the trainable variables for the generator and discriminator\n",
        "theta_D = [var for var in discriminator.trainable_variables if 'dis' in var.name]\n",
        "theta_G = [var for var in generator.trainable_variables if 'gen' in var.name]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z007mzjBNCvm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Assume generator and discriminator are defined as tf.keras.Model instances\n",
        "generator = ...  # Your generator model definition here\n",
        "discriminator = ...  # Your discriminator model definition here\n",
        "\n",
        "# Define optimizers\n",
        "D_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "G_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# Training step function using GradientTape\n",
        "@tf.function\n",
        "def training_step(real_images, noise):\n",
        "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
        "        # Generate fake images from noise\n",
        "        fake_images = generator(noise, training=True)\n",
        "\n",
        "        # Discriminator outputs\n",
        "        D_logits_real = discriminator(real_images, training=True)\n",
        "        D_logits_fake = discriminator(fake_images, training=True)\n",
        "\n",
        "        # Calculate losses\n",
        "        D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            logits=D_logits_real, labels=tf.ones_like(D_logits_real)\n",
        "        ))\n",
        "        D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            logits=D_logits_fake, labels=tf.zeros_like(D_logits_fake)\n",
        "        ))\n",
        "        D_loss = D_loss_real + D_loss_fake\n",
        "\n",
        "        G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            logits=D_logits_fake, labels=tf.ones_like(D_logits_fake)\n",
        "        ))\n",
        "\n",
        "    # Calculate gradients\n",
        "    D_gradients = disc_tape.gradient(D_loss, discriminator.trainable_variables)\n",
        "    G_gradients = gen_tape.gradient(G_loss, generator.trainable_variables)\n",
        "\n",
        "    # Apply gradients\n",
        "    D_optimizer.apply_gradients(zip(D_gradients, discriminator.trainable_variables))\n",
        "    G_optimizer.apply_gradients(zip(G_gradients, generator.trainable_variables))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-0ZRbeHN_Ae"
      },
      "outputs": [],
      "source": [
        "# Use TensorFlow 2.x compatible initializer\n",
        "init = tf.compat.v1.global_variables_initializer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "rwCxhXI2ORYg",
        "outputId": "bc9192cc-4e58-4cee-8a1b-0aa93fa14ef0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py:681: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Discriminator Loss: 1.9130250166199403e-06, Generator Loss: 13.887944221496582\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set training parameters\n",
        "batch_size = 100\n",
        "num_epochs = 1000\n",
        "z_dim = 100\n",
        "image_dim = 784  # 28x28 flattened\n",
        "\n",
        "# Define the generator model\n",
        "def build_generator(z_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(256, activation='relu', input_shape=(z_dim,)),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dense(image_dim, activation='tanh')  # Use 'tanh' activation for [-1, 1] output\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define the discriminator model\n",
        "def build_discriminator(image_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(1024, activation='relu', input_shape=(image_dim,)),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Instantiate the generator and discriminator\n",
        "generator = build_generator(z_dim)\n",
        "discriminator = build_discriminator(image_dim)\n",
        "\n",
        "# Loss function and optimizers\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "D_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "G_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# Loss functions for discriminator and generator\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# Training function without @tf.function (for eager execution)\n",
        "def train_step(real_images):\n",
        "    noise = tf.random.uniform([batch_size, z_dim], -1.0, 1.0)\n",
        "\n",
        "    with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(real_images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "        g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Calculate gradients for both discriminator and generator\n",
        "    d_gradients = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
        "    g_gradients = g_tape.gradient(g_loss, generator.trainable_variables)\n",
        "\n",
        "    # Apply gradients using the Adam optimizer\n",
        "    D_optimizer.apply_gradients(zip(d_gradients, discriminator.trainable_variables))\n",
        "    G_optimizer.apply_gradients(zip(g_gradients, generator.trainable_variables))\n",
        "\n",
        "    return d_loss, g_loss, generated_images\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = (x_train.reshape(-1, image_dim) / 255.0) * 2 - 1  # Normalize to [-1, 1]\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Shuffle and create batches for each epoch\n",
        "    np.random.shuffle(x_train)\n",
        "    num_batches = x_train.shape[0] // batch_size\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        batch_images = x_train[i * batch_size: (i + 1) * batch_size]\n",
        "        d_loss, g_loss, generated_images = train_step(batch_images)\n",
        "\n",
        "    # Every 100 epochs, print the losses and generate an image\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch: {epoch}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}\")\n",
        "\n",
        "        # Generate and display a sample image\n",
        "        noise = tf.random.uniform([1, z_dim], -1.0, 1.0)\n",
        "        generated_image = generator(noise, training=False)  # Make sure to set training=False for inference\n",
        "\n",
        "        # Convert the tensor to a numpy array and reshape for display\n",
        "        plt.imshow(generated_image[0].numpy().reshape(28, 28), cmap='gray')\n",
        "        plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8LTyVxvTXO4cIL3gf4ldH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}